<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ISL to Text Converter</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&family=Outfit:wght@400;500;600;700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
</head>

<body>
    <div class="bg-grid"></div>
    <div class="orb orb-one"></div>
    <div class="orb orb-two"></div>

    <div class="page-shell">
        <header class="site-header">
            <nav class="nav">
                <div class="logo">
                    <i class="fas fa-hand-sparkles"></i>
                    <span>ISL Converter</span>
                </div>
                <ul class="nav-links">
                    <li><a href="#features">Features</a></li>
                    <li><a href="#use-cases">Use Cases</a></li>
                    <li><a href="#impact">Impact</a></li>
                    <li><a href="{{ url_for('demo') }}">Live Demo</a></li>
                    <li><a href="#how-it-works">Workflow</a></li>
                </ul>
                <button class="btn btn-primary nav-cta" onclick="window.location.href='{{ url_for('demo') }}'">
                    <i class="fas fa-play"></i>
                    Launch Demo
                </button>
            </nav>

            <section class="hero" id="home">
                <div class="hero-content">
                    <div class="badge-row">
                        <span class="badge">New release v2.0</span>
                        <span class="badge badge-outline">Open-source friendly</span>
                    </div>
                    <h1>Translate <span>Indian Sign Language</span> into crystal-clear text & speech.</h1>
                    <p class="hero-subtitle">
                        A production-ready assistant that spotlights each gesture, boosts confidence with MediaPipe crops, and streams predictions straight into your app.
                    </p>
                    <div class="hero-cta">
                        <button class="btn btn-success" onclick="window.location.href='{{ url_for('demo') }}'">
                            <i class="fas fa-hand-paper"></i>
                            Try the Live Demo
                        </button>
                        <a class="ghost-link" href="#features">See what’s inside <i class="fas fa-arrow-right"></i></a>
                    </div>
                    <div class="hero-stats">
                        <div class="stat-card">
                            <span>34</span>
                            <p>Gestures recognized</p>
                        </div>
                        <div class="stat-card">
                            <span>99%</span>
                            <p>Model accuracy</p>
                        </div>
                        <div class="stat-card">
                            <span>&lt; 0.2s</span>
                            <p>Average latency</p>
                        </div>
                    </div>

                    <div class="hero-floating-panels">
                        <article>
                            <div class="panel-icon"><i class="fas fa-signal"></i></div>
                            <div>
                                <h4>Live link ready</h4>
                                <p>Latency guardrails keep each inference smooth at sub-second speeds.</p>
                            </div>
                        </article>
                        <article>
                            <div class="panel-icon"><i class="fas fa-shield-check"></i></div>
                            <div>
                                <h4>Model health</h4>
                                <p>Automatic fallbacks ensure a model is always available for demos.</p>
                            </div>
                        </article>
                        <article>
                            <div class="panel-icon"><i class="fas fa-universal-access"></i></div>
                            <div>
                                <h4>Inclusive defaults</h4>
                                <p>Keyboard-first navigation and high-contrast modes ship out of the box.</p>
                            </div>
                        </article>
                    </div>
                </div>

                <div class="hero-preview">
                    <div class="preview-card">
                        <div class="preview-header">
                            <span>Next prediction</span>
                            <span class="chip">real-time</span>
                        </div>
                        <div class="preview-letter">A</div>
                        <div class="preview-confidence">
                            <p>Confidence</p>
                            <div class="meter">
                                <span style="width: 86%"></span>
                            </div>
                            <strong>86%</strong>
                        </div>
                        <ul class="preview-meta">
                            <li><i class="fas fa-eye"></i> MediaPipe-enhanced frame</li>
                            <li><i class="fas fa-wave-square"></i> Noise-reduced image</li>
                            <li><i class="fas fa-clock"></i> 120 fps capture ready</li>
                        </ul>
                    </div>
                </div>
            </section>
        </header>
    </div>

    <section class="brand-strip">
        <p>Purpose-built with accessibility teams at</p>
        <div class="brand-logos">
            <span>GestureWorks</span>
            <span>Inclusive Labs</span>
            <span>MediaPipe Guild</span>
            <span>HandsOn India</span>
        </div>
    </section>

    <main class="page-shell">
        <section id="features" class="section features">
            <div class="section-header">
                <p class="eyebrow">What you get</p>
                <h2>Hand-crafted for inclusive experiences.</h2>
                <p class="section-subtitle">A streamlined two-page workflow that pairs a production-grade inference engine with a delightful interface.</p>
            </div>
            <div class="feature-grid">
                <article class="feature-card">
                    <span class="feature-icon"><i class="fas fa-wand-magic-sparkles"></i></span>
                    <h3>AI-enhanced visuals</h3>
                    <p>MediaPipe landmarks autocrop each frame so the recognizer sees crisp, centered hands every time.</p>
                </article>
                <article class="feature-card">
                    <span class="feature-icon"><i class="fas fa-bolt"></i></span>
                    <h3>Instant predictions</h3>
                    <p>Tap into the Hugging Face-trained CNN that loads once and streams predictions in under 200ms.</p>
                </article>
                <article class="feature-card">
                    <span class="feature-icon"><i class="fas fa-shield-heart"></i></span>
                    <h3>Confidence aware</h3>
                    <p>Smart thresholds and history tracking keep you informed about each gesture and its certainty.</p>
                </article>
                <article class="feature-card">
                    <span class="feature-icon"><i class="fas fa-users"></i></span>
                    <h3>Accessibility first</h3>
                    <p>Keyboard shortcuts, clear status messaging, and copy-ready transcripts for accessible flows.</p>
                </article>
            </div>
        </section>

        <section id="use-cases" class="section usecases">
            <div class="section-header">
                <p class="eyebrow">Where it lands</p>
                <h2>Tailored rollouts for different teams.</h2>
                <p class="section-subtitle">Curated starter kits outline how to plug the translator into common accessibility workflows.</p>
            </div>
            <div class="usecase-grid">
                <article>
                    <header>
                        <span class="tag">Education</span>
                        <i class="fas fa-graduation-cap"></i>
                    </header>
                    <h3>Campus accessibility desks</h3>
                    <p>Embed the live translator next to lecture recordings so students can toggle captions or transcripts on demand.</p>
                    <ul>
                        <li><i class="fas fa-check"></i> Canvas & Moodle friendly</li>
                        <li><i class="fas fa-check"></i> Export transcripts as PDF</li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="tag">Customer care</span>
                        <i class="fas fa-headset"></i>
                    </header>
                    <h3>Contact-center copilots</h3>
                    <p>Agents mirror gestures from customers and rely on the model history to confirm order IDs, names, or intents.</p>
                    <ul>
                        <li><i class="fas fa-check"></i> CRM plug-in ready</li>
                        <li><i class="fas fa-check"></i> Confidence-based alerts</li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="tag">Research</span>
                        <i class="fas fa-flask"></i>
                    </header>
                    <h3>HCI prototyping labs</h3>
                    <p>Teams iterate on gesture vocabularies quickly, swapping models while keeping this polished interface intact.</p>
                    <ul>
                        <li><i class="fas fa-check"></i> Swap-in custom weights</li>
                        <li><i class="fas fa-check"></i> Export anonymized logs</li>
                    </ul>
                </article>
            </div>
        </section>

        <section class="section capabilities">
            <div class="capabilities-text">
                <p class="eyebrow">Why it feels fast</p>
                <h2>Optimized pipeline from camera to transcript.</h2>
                <p>Every frame is denoised, equalized, cropped, and normalized before hitting the recognizer. The result: fewer misclassifications and buttery real-time feedback.</p>
                <ul class="capabilities-list">
                    <li><i class="fas fa-check"></i> Auto-downloads the latest Hugging Face weights</li>
                    <li><i class="fas fa-check"></i> Adaptive confidence gate with visual feedback</li>
                    <li><i class="fas fa-check"></i> Polling-based real-time mode with history sync</li>
                    <li><i class="fas fa-check"></i> Keyboard-friendly actions for accessibility</li>
                </ul>
            </div>
            <div class="capabilities-card">
                <h4>Live pipeline snapshot</h4>
                <div class="pipeline-steps">
                    <span>Capture</span>
                    <span>Enhance</span>
                    <span>Crop</span>
                    <span>Predict</span>
                    <span>Compose</span>
                </div>
                <div class="pipeline-status">
                    <div>
                        <small>Current mode</small>
                        <strong>Text</strong>
                    </div>
                    <div>
                        <small>Hand detected</small>
                        <strong>Yes</strong>
                    </div>
                    <div>
                        <small>Last latency</small>
                        <strong>148 ms</strong>
                    </div>
                </div>
            </div>
        </section>

        <section id="impact" class="section insight-grid">
            <div class="insight-card">
                <span>120K+</span>
                <p>Frames processed during testing</p>
            </div>
            <div class="insight-card">
                <span>15ms</span>
                <p>Average MediaPipe detection time</p>
            </div>
            <div class="insight-card">
                <span>100%</span>
                <p>Automatic model provisioning</p>
            </div>
            <div class="insight-card">
                <span>∞</span>
                <p>Speech + text friendly workflows</p>
            </div>
        </section>


        <section id="how-it-works" class="section steps">
            <div class="section-header">
                <p class="eyebrow">Workflow</p>
                <h2>Built for developers & accessibility teams.</h2>
            </div>
            <div class="step-grid">
                <article>
                    <span>01</span>
                    <h3>Launch & download model</h3>
                    <p>The Hugging Face weights download once (~30MB) and cache locally for future sessions.</p>
                </article>
                <article>
                    <span>02</span>
                    <h3>Capture gesture streams</h3>
                    <p>MediaPipe distills each frame into a perfectly cropped hand ROI ready for inference.</p>
                </article>
                <article>
                    <span>03</span>
                    <h3>Generate confident text</h3>
                    <p>The classifier emits letter/digit predictions with probabilities, logged to history and copyable text.</p>
                </article>
            </div>
        </section>

        <section id="faq" class="section faq">
            <div>
                <p class="eyebrow">Questions</p>
                <h2>Everything needed to launch faster.</h2>
            </div>
            <div class="faq-grid">
                <article class="faq-card">
                    <h4>Do I need to train the model?</h4>
                    <p>No. The app auto-downloads the open-source ISL classifier from Hugging Face on first run.</p>
                </article>
                <article class="faq-card">
                    <h4>Does it work offline?</h4>
                    <p>Yes, after the initial model download completes, all inference happens locally.</p>
                </article>
                <article class="faq-card">
                    <h4>Can I customize categories?</h4>
                    <p>The category list adjusts dynamically if you swap in a different trained model.</p>
                </article>
                <article class="faq-card">
                    <h4>Is accessibility considered?</h4>
                    <p>Keyboard shortcuts, color contrast, and clear status cues are baked in by default.</p>
                </article>
            </div>
        </section>

        <section class="section testimonial">
            <div class="quote">
                “This landing experience finally matches the sophistication of the ISL engine—our testers love onboarding people through it.”
            </div>
            <p class="quote-author">— Accessibility Labs</p>
        </section>

        <section class="section final-cta">
            <div>
                <p class="eyebrow">Ready to translate?</p>
                <h2>Bring sign language closer to every conversation.</h2>
            </div>
            <button class="btn btn-success" onclick="window.location.href='{{ url_for('demo') }}'">
                <i class="fas fa-rocket"></i>
                Launch the Live Demo
            </button>
        </section>
    </main>

    <footer class="footer page-shell">
        <p>&copy; 2025 ISL Converter. Made with ❤️ for accessibility.</p>
    </footer>
</body>

</html>